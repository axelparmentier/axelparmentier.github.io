@article{cohenFutureMemoriesAre2023,
  title = {Future Memories Are Not Needed for Large Classes of {{POMDPs}}},
  author = {Cohen, Victor and Parmentier, Axel},
  year = {2023},
  month = mar,
  journal = {Operations Research Letters},
  abbr= {Article},
  arxiv = {2205.02580},
  doi={https://doi.org/10.1016/j.orl.2023.02.011},
  code={https://github.com/Victor2175/POMDP_SMFpolicies},
  abstract = {Optimal policies for partially observed Markov decision processes (POMDPs) are history-dependent: Decisions are made based on the entire history of observations. Memoryless policies, which take decisions based on the last observation only, are generally considered useless in the literature because we can construct POMDP instances for which optimal memoryless policies are arbitrarily worse than history-dependent ones. Our purpose is to challenge this belief. We show that optimal memoryless policies can be computed efficiently using mixed integer linear programming (MILP), and perform reasonably well on a wide range of instances from the literature. When strengthened with valid inequalities, the linear relaxation of this MILP provides high quality upper-bounds on the value of an optimal history dependent policy. Furthermore, when used with a finite horizon POMDP problem with memoryless policies as rolling optimization problem, a model predictive control approach leads to an efficient history-dependent policy, which we call the short memory in the future (SMF) policy. Basically, the SMF policy leverages these memoryless policies to build an approximation of the Bellman value function. Numerical experiments show the efficiency of our approach on benchmark instances from the literature.}
}

@article{cohenIntegerProgrammingWeakly2020,
  title = {Integer Programming for Weakly Coupled Stochastic Dynamic Programs with Partial Information},
  author = {Cohen, Victor and Parmentier, Axel},
  year = {2020},
  month = dec,
  abbr = {Technical Report},
  arxiv = {2012.00645},
  primaryclass = {math},
  abstract = {This paper introduces algorithms for problems where a decision maker has to control a system composed of several components and has access to only partial information on the state of each component. Such problems are difficult because of the partial observations, and because of the curse of dimensionality that appears when the number of components increases. Partially observable Markov decision processes (POMDPs) have been introduced to deal with the first challenge, while weakly coupled stochastic dynamic programs address the second. Drawing from these two branches of the literature, we introduce the notion of weakly coupled POMDPs. The objective is to find a policy maximizing the total expected reward over a finite horizon. Our algorithms rely on two ingredients. The first, which can be used independently, is a mixed integer linear formulation for generic POMDPs that computes an optimal memoryless policy. The formulation is strengthened with valid cuts based on a probabilistic interpretation of the dependence between random variables, and its linear relaxation provide a practically tight upper bound on the value of an optimal history-dependent policies. The second is a collection of mathematical programming formulations and algorithms which provide tractable policies and upper bounds for weakly coupled POMDPs. Lagrangian relaxations, fluid approximations, and almost sure constraints relaxations enable to break the curse of dimensionality. We test our generic POMDPs formulations on benchmark instance forms the literature, and our weakly coupled POMDP algorithms on a maintenance problem. Numerical experiments show the efficiency of our approach.},
  keywords = {Mathematics - Optimization and Control},
}

@article{cohenTwoGeneralizationsMarkov2019,
  title = {Two Generalizations of {{Markov}} Blankets},
  author = {Cohen, Victor and Parmentier, Axel},
  year = {2019},
  month = mar,
  arxiv = {1903.03538},
  abbr = {Technical Report},
  primaryclass = {cs, math},
  abstract = {In a probabilistic graphical model on a set of variables \$V\$, the Markov blanket of a random vector \$B\$ is the minimal set of variables conditioned to which \$B\$ is independent from the remaining of the variables \$V \textbackslash backslash B\$. We generalize Markov blankets to study how a set \$C\$ of variables of interest depends on\textasciitilde\$B\$. Doing that, we must choose if we authorize vertices of \$C\$ or vertices of \$V \textbackslash backslash C\$ in the blanket. We therefore introduce two generalizations. The Markov blanket of \$B\$ in \$C\$ is the minimal subset of \$C\$ conditionally to which \$B\$ and \$C\$ are independent. It is naturally interpreted as the inner boundary through which \$C\$ depends on \$B\$, and finds applications in feature selection. The Markov blanket of \$B\$ in the direction of \$C\$ is the nearest set to \$B\$ among the minimal sets conditionally to which ones \$B\$ and \$C\$ are independent, and finds applications in causality. It is the outer boundary of \$B\$ in the direction of \$C\$. We provide algorithms to compute them that are not slower than the usual algorithms for finding a d-separator in a directed graphical model. All our definitions and algorithms are provided for directed and undirected graphical models.},
  keywords = {Computer Science - Discrete Mathematics,Mathematics - Combinatorics,Mathematics - Probability},
}

@misc{dalleLearningCombinatorialOptimization2022,
  title = {Learning with {{Combinatorial Optimization Layers}}: A {{Probabilistic Approach}}},
  shorttitle = {Learning with {{Combinatorial Optimization Layers}}},
  author = {Dalle, Guillaume and Baty, L{\'e}o and Bouvier, Louis and Parmentier, Axel},
  year = {2022},
  month = jul,
  number = {arXiv:2207.13513},
  arxiv = {2207.13513},
  abbr = {Preprint},
  code = {https://github.com/axelparmentier/InferOpt.jl},
  primaryclass = {cs, math, stat},
  doi = {10.48550/arXiv.2207.13513},
  abstract = {Combinatorial optimization (CO) layers in machine learning (ML) pipelines are a powerful tool to tackle data-driven decision tasks, but they come with two main challenges. First, the solution of a CO problem often behaves as a piecewise constant function of its objective parameters. Given that ML pipelines are typically trained using stochastic gradient descent, the absence of slope information is very detrimental. Second, standard ML losses do not work well in combinatorial settings. A growing body of research addresses these challenges through diverse methods. Unfortunately, the lack of well-maintained implementations slows down the adoption of CO layers. In this paper, building upon previous works, we introduce a probabilistic perspective on CO layers, which lends itself naturally to approximate differentiation and the construction of structured losses. We recover many approaches from the literature as special cases, and we also derive new ones. Based on this unifying perspective, we present InferOpt.jl, an open-source Julia package that 1) allows turning any CO oracle with a linear objective into a differentiable layer, and 2) defines adequate losses to train pipelines containing such layers. Our library works with arbitrary optimization algorithms, and it is fully compatible with Julia's ML ecosystem. We demonstrate its abilities using a pathfinding problem on video game maps.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Mathematics - Optimization and Control,Statistics - Machine Learning},
}

@inproceedings{ferrariniLearningPrimalHeuristics2025,
  title = {Learning {{Primal Heuristics}} for 0--1 {{Knapsack Interdiction Problems}}},
  booktitle = {22nd {{International Conference}} on the {{Integration}} of {{Constraint Programming}}, {{Artificial Intelligence}}, and {{Operations Research}}},
  author = {Ferrarini, Luca and Gualandi, Stefano and Moro, Letizia and Parmentier, Axel},
  year = {2025},
  month = nov,
  urldate = {2025-02-12},
  abbr = {Proceedings},
  pdf = {https://openreview.net/forum?id=wnf2lD84i2},
  abstract = {In interdiction problems, two opposing decision-makers act sequentially: the leader plays first by selecting items to restrict the choices of the follower, while the follower selects those that maximize her profit from the remaining items. In knapsack interdiction, both decision-makers face different budget constraints. We propose a single-level approximation of the leader-follower problem, and interpret it as a combinatorial optimization layer in a machine learning pipeline. The ML pipeline includes a Generalized Linear Model as the first layer, which predicts the parameters of the single-level problem. Using a perturbation approach, we regularize the single-level problem, which enables to make it differentiable and provides a natural loss to train the model. Once trained, the pipeline provides effective ordering heuristics to solve Knapsack Interdiction problems. Extensive computational results on benchmarks from the literature show that the learned ML-based primal heuristics are extremely fast and compute solutions with a small optimality gap.},
  langid = {english}
}

@misc{bouvier2025primaldualalgorithmcontextualstochastic,
      title={Primal-dual algorithm for contextual stochastic combinatorial optimization}, 
      author={Louis Bouvier and Thibault Prunet and Vincent Lecl√®re and Axel Parmentier},
      year={2025},
      eprint={2505.04757},
      arxiv={2505.04757},
      abbr={Preprint},
      month=may,
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2505.04757},
      abstract={
      This paper introduces a novel approach to contextual stochastic optimization, integrating operations research and machine learning to address decision-making under uncertainty. Traditional methods often fail to leverage contextual information, which underscores the necessity for new algorithms. In this study, we utilize neural networks with combinatorial optimization layers to encode policies. Our goal is to minimize the empirical risk, which is estimated from past data on uncertain parameters and contexts. To that end, we present a surrogate learning problem and a generic primal-dual algorithm that is applicable to various combinatorial settings in stochastic optimization. Our approach extends classic Fenchel-Young loss results and introduces a new regularization method using sparse perturbations on the distribution simplex. This allows for tractable updates in the original space and can accommodate diverse objective functions. We demonstrate the linear convergence of our algorithm under certain conditions and provide a bound on the non-optimality of the resulting policy in terms of the empirical risk. Experiments on a contextual stochastic minimum weight spanning tree problem show that our algorithm is efficient and scalable, achieving performance comparable to imitation learning of solutions computed using an expensive Lagrangian-based heuristic.} 
}

@misc{vivier-ardissonLearningLocalSearch2025,
  title = {Learning with {{Local Search MCMC Layers}}},
  author = {{Vivier-Ardisson}, Germain and Blondel, Mathieu and Parmentier, Axel},
  year = {2025},
  month = may,
  number = {arXiv:2505.14240},
  abbr = {Preprint},
  arxiv = {2505.14240},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2505.14240},
  urldate = {2025-05-21},
  abstract = {Integrating combinatorial optimization layers into neural networks has recently attracted significant research interest. However, many existing approaches lack theoretical guarantees or fail to perform adequately when relying on inexact solvers. This is a critical limitation, as many operations research problems are NP-hard, often necessitating the use of neighborhood-based local search heuristics. These heuristics iteratively generate and evaluate candidate solutions based on an acceptance rule. In this paper, we introduce a theoretically-principled approach for learning with such inexact combinatorial solvers. Inspired by the connection between simulated annealing and Metropolis-Hastings, we propose to transform problem-specific neighborhood systems used in local search heuristics into proposal distributions, implementing MCMC on the combinatorial space of feasible solutions. This allows us to construct differentiable combinatorial layers and associated loss functions. Replacing an exact solver by a local search strongly reduces the computational burden of learning on many applications. We demonstrate our approach on a large-scale dynamic vehicle routing problem with time windows.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning}
}

@misc{hoppeStructuredReinforcementLearning2025,
  title = {Structured {{Reinforcement Learning}} for {{Combinatorial Decision-Making}}},
  author = {Hoppe, Heiko and Baty, L{\'e}o and Bouvier, Louis and Parmentier, Axel and Schiffer, Maximilian},
  year = {2025},
  month = may,
  number = {arXiv:2505.19053},
  abbr = {Preprint},
  arxiv = {2505.19053},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2505.19053},
  urldate = {2025-05-27},
  code = {https://github.com/tumBAIS/Structured-RL},
  abstract = {Reinforcement learning (RL) is increasingly applied to real-world problems involving complex and structured decisions, such as routing, scheduling, and assortment planning. These settings challenge standard RL algorithms, which struggle to scale, generalize, and exploit structure in the presence of combinatorial action spaces. We propose Structured Reinforcement Learning (SRL), a novel actor-critic framework that embeds combinatorial optimization layers into the actor neural network. We enable end-to-end learning of the actor via Fenchel-Young losses and provide a geometric interpretation of SRL as a primal-dual algorithm in the dual of the moment polytope. Across six environments with exogenous and endogenous uncertainty, SRL matches or surpasses the performance of unstructured RL and imitation learning on static tasks and improves over these baselines by up to 92\% on dynamic problems, with improved stability and convergence speed.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Mathematics - Optimization and Control,Statistics - Machine Learning}
}



@misc{nouliPreferenceawareCompensationPolicies2025,
  title = {Preference-Aware Compensation Policies for Crowdsourced on-Demand Services},
  author = {Nouli, Georgina and Parmentier, Axel and Schiffer, Maximilian},
  year = {2025},
  month = feb,
  number = {arXiv:2502.05060},
  abbr = {Preprint},
  eprint = {2502.05060},
  primaryclass = {cs},
  publisher = {arXiv},
  arxiv = {2502.05060},
  urldate = {2025-02-10},
  abstract = {Crowdsourced on-demand services offer benefits such as reduced costs, faster service fulfillment times, greater adaptability, and contributions to sustainable urban transportation in on-demand delivery contexts. However, the success of an on-demand platform that utilizes crowdsourcing relies on finding a compensation policy that strikes a balance between creating attractive offers for gig workers and ensuring profitability. In this work, we examine a dynamic pricing problem for an on-demand platform that sets request-specific compensation of gig workers in a discrete-time framework, where requests and workers arrive stochastically. The operator's goal is to determine a compensation policy that maximizes the total expected reward over the time horizon. Our approach introduces compensation strategies that explicitly account for gig worker request preferences. To achieve this, we employ the Multinomial Logit model to represent the acceptance probabilities of gig workers, and, as a result, derive an analytical solution that utilizes post-decision states. Subsequently, we integrate this solution into an approximate dynamic programming algorithm. We compare our algorithm against benchmark algorithms, including formula-based policies and an upper bound provided by the full information linear programming solution. Our algorithm demonstrates consistent performance across diverse settings, achieving improvements of at least 2.5-7.5\% in homogeneous gig worker populations and 9\% in heterogeneous populations over benchmarks, based on fully synthetic data. For real-world data, it surpasses benchmarks by 8\% in weak and 20\% in strong location preference scenarios.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Mathematics - Optimization and Control}
}


@article{kruberLearningWhenUse2017,
  title = {Learning {{When}} to {{Use}} a {{Decomposition}}},
  booktitle = {Integration of {{AI}} and {{OR Techniques}} in {{Constraint Programming}}},
  journal = {Proceedings of 14th International Conference on the Integration of Artificial Intelligence and Operations Research Techniques in Constraint Programming (CPAIOR 2017)},
  author = {Kruber, Markus and L{\"u}bbecke, Marco E. and Parmentier, Axel},
  editor = {Salvagnin, Domenico and Lombardi, Michele},
  year = {2017},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {202--210},
  abbr = {Proceedings},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-319-59776-8_16},
  abstract = {Applying a Dantzig-Wolfe decomposition to a mixed-integer program (MIP) aims at exploiting an embedded model structure and can lead to significantly stronger reformulations of the MIP. Recently, automating the process and embedding it in standard MIP solvers have been proposed, with the detection of a decomposable model structure as key element. If the detected structure reflects the (usually unknown) actual structure of the MIP well, the solver may be much faster on the reformulated model than on the original. Otherwise, the solver may completely fail. We propose a supervised learning approach to decide whether or not a reformulation should be applied, and which decomposition to choose when several are possible. Preliminary experiments with a MIP solver equipped with this knowledge show a significant performance improvement on structured instances, with little deterioration on others.},
  isbn = {978-3-319-59776-8},
  langid = {english},
  keywords = {Automatic Dantzig-Wolfe decomposition,Branch-and-price,Column generation,Mixed-integer programming,Supervised learning},
  annotation = {ZSCC: NoCitationData[s0]},
}

@article{kruberResourceConstrainedShortest2018,
  title = {Resource Constrained Shortest Path Algorithm for {{EDF}} Short-Term Thermal Production Planning Problem},
  author = {Kruber, Markus and Parmentier, Axel and Benchimol, Pascal},
  year = {2018},
  month = sep,
  arxiv = {1809.00548},
  eprinttype = {arxiv},
  primaryclass = {math},
  abbr = {Technical Report},
  abstract = {Unit commitment problem on an electricity network consists in choosing the production plan of the plants (units) of a company in order to meet demand constraints. It is generally solved using a decomposition approach where demand constraints are relaxed, resulting in one pricing subproblem for each unit. In this paper we focus on the pricing subproblem for thermal units at EDF, a major French electricity producer. Our objective is to determine an optimal two-day production plan that minimizes the overall cost while respecting several non-linear operational constraints. The pricing problem is generally solved by dynamic programming. However, due to the curse of dimensionality, dynamic programming reaches its limits when extra-constraints have to be enforced. We model the subproblem as a resource constrained shortest path (RCSP) problem. Leveraging on RCSP algorithms recently introduced by the second author, we obtain an order of magnitude speed-up with respect to traditional RCSP algorithms.},
  archiveprefix = {arXiv},
  keywords = {90B99,G.1.6,G.2.2,Mathematics - Optimization and Control},
}

@article{parmentierAircraftRoutingCrew2020,
  title = {Aircraft Routing and Crew Pairing: {{Updated}} Algorithms at {{Air France}}},
  shorttitle = {Aircraft Routing and Crew Pairing},
  author = {Parmentier, Axel and Meunier, Fr{\'e}d{\'e}ric},
  year = {2020},
  month = jun,
  journal = {Omega},
  arxiv = {1706.06901},
  abbr = {Article},
  volume = {93},
  pages = {102073},
  issn = {0305-0483},
  doi = {10.1016/j.omega.2019.05.009},
  abstract = {Aircraft routing and crew pairing problems aim at building the sequences of flight legs operated respectively by airplanes and by crews of an airline. Given their impact on airlines operating costs, both have been extensively studied for decades. Our goal is to provide reliable and easy to maintain frameworks for both problems at Air France. We propose simple approaches to deal with Air France current setting. For routing, we introduce an exact compact IP formulation that can be solved to optimality by current MIP solvers in at most a few minutes even on Air France largest instances. Regarding crew pairing, we provide a methodology to model the column generation pricing subproblem within a new resource constrained shortest path framework recently introduced by the first author. This new framework, which can be used as a black-box, leverages on bounds to discard partial solutions and speed-up the resolution. The resulting approach enables to solve to optimality Air France largest instances. Recent literature has focused on integrating aircraft routing and crew pairing problems. As a side result, we are able to solve to near optimality large industrial instances of the integrated problem by combining the aforementioned algorithms within a simple cut generating method.},
  langid = {english},
  keywords = {Airline management,Column generation,Cut generation,Shortest path algorithm},
}

@article{parmentierAlgorithmsNonlinearStochastic2019,
  title = {Algorithms for Non-Linear and Stochastic Resource Constrained Shortest Path},
  author = {Parmentier, Axel},
  year = {2019},
  month = apr,
  journal = {Mathematical Methods of Operations Research},
  abbr = {Article},
  volume = {89},
  number = {2},
  pages = {281--317},
  issn = {1432-5217},
  arxiv = {1504.07880},
  doi = {10.1007/s00186-018-0649-x},
  abstract = {Resource constrained shortest path problems are usually solved thanks to a smart enumeration of all the non-dominated paths. Recent improvements of these enumeration algorithms rely on the use of bounds on path resources to discard partial solutions. The quality of the bounds determines the performance of the algorithm. The main contribution of this paper is to introduce a standard procedure to generate bounds on paths resources in a general setting which covers most resource constrained shortest path problems, among which stochastic versions. In that purpose, we introduce a generalization of the resource constrained shortest path problem where the resources are taken in a monoid. The resource of a path is the monoid sum of the resources of its arcs. The problem consists in finding a path whose resource minimizes a non-decreasing cost function of the path resource among the paths that respect a given constraint. Enumeration algorithms are generalized to this framework. We use lattice theory to provide polynomial procedures to find good quality bounds. These procedures solve a generalization of the algebraic path problem, where arc resources belong to a lattice ordered monoid. The practical efficiency of the approach is proved through an extensive numerical study on some deterministic and stochastic resource constrained shortest path problems.},
  langid = {english},
  annotation = {ZSCC: 0000011},
}

@article{forelDonExplainNoise2023,
  title = {Don't {{Explain Noise}}: {{Robust Counterfactuals}} for {{Randomized Ensembles}}},
  shorttitle = {Don't {{Explain Noise}}},
  author = {Forel, Alexandre and Parmentier, Axel and Vidal, Thibaut},
  year = {2024},
  month = may,
  number = {arXiv:2205.14116},
  arxiv = {2205.14116},
  abbr = {Proceedings},
  journal = {Proceedings of 21st International Conference on the Integration of Artificial Intelligence and Operations Research Techniques in Constraint Programming (CPAIOR 2024)},
  primaryclass = {cs, math},
  publisher = {{arXiv}},
  doi = {https://doi.org/10.1007/978-3-031-60597-0_19},
  abstract = {Counterfactual explanations describe how to modify a feature vector in order to flip the outcome of a trained classifier. Obtaining robust counterfactual explanations is essential to provide valid algorithmic recourse and meaningful explanations. We study the robustness of explanations of randomized ensembles, which are always subject to algorithmic uncertainty even when the training data is fixed. We formalize the generation of robust counterfactual explanations as a probabilistic problem and show the link between the robustness of ensemble models and the robustness of base learners. We develop a practical method with good empirical performance and support it with theoretical guarantees for ensembles of convex base learners. Our results show that existing methods give surprisingly low robustness: the validity of naive counterfactuals is below \$50\textbackslash\%\$ on most data sets and can fall to \$20\textbackslash\%\$ on problems with many features. In contrast, our method achieves high robustness with only a small increase in the distance from counterfactual explanations to their initial observations.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Mathematics - Optimization and Control},
  file = {/home/axel/zotero-library/Forel et al_2023_Don't Explain Noise.pdf}
}

@article{parmentierElectricVehicleFleets2023,
  title = {Electric {{Vehicle Fleets}}: {{Scalable Route}} and {{Recharge Scheduling Through Column Generation}}},
  shorttitle = {Electric {{Vehicle Fleets}}},
  author = {Parmentier, Axel and Martinelli, Rafael and Vidal, Thibaut},
  year = {2023},
  month = mar,
  journal = {Transportation Science},
  abbr = {Article},
  arxiv = {2104.03823},
  code = {https://github.com/axelparmentier/ElectricalVSP-ColumnGeneration},
  publisher = {INFORMS},
  issn = {0041-1655},
  doi = {10.1287/trsc.2023.1199},
  urldate = {2023-03-21},
  abstract = {The rise of battery-powered vehicles has led to many new technical and methodological hurdles. Among these, the efficient planning of an electric fleet to fulfill passenger transportation requests still represents a major challenge. This is because of the specific constraints of electric vehicles, bound by their battery autonomy and necessity of recharge planning, and the large scale of the operations, which challenges existing optimization algorithms. The purpose of this paper is to introduce a scalable column generation approach for routing and scheduling in this context. Our algorithm relies on four main ingredients: (i) a multigraph reformulation of the problem based on a characterization of nondominated charging arcs, (ii) an efficient bidirectional pricing algorithm using tight backward bounds, (iii) sparsification approaches permitting to decrease the size of the subjacent graphs dramatically, and (iv) a diving heuristic, which locates near-optimal solutions in a fraction of the time needed for a complete branch-and-price. Through extensive computational experiments, we demonstrate that our approach significantly outperforms previous algorithms for this setting, leading to accurate solutions for problems counting several hundreds of requests. Funding: This work was supported by Conselho Nacional de Desenvolvimento Cient{\'i}fico e Tecnol{\'o}gico [Grants 08528/2018-2 and 315361/2020-4], Coordena{\c c}{\~a}o de Aperfei{\c c}oamento de Pessoal de N{\'i}vel Superior [Finance Code 001], and Funda{\c c}{\~a}o Carlos Chagas Filho de Amparo {\`a} Pesquisa do Estado do Rio de Janeiro [Grants E-26/010.002232/2019 and E-26/202.790/2019]. Supplemental Material: The online appendix is available at https://doi.org/10.1287/trsc.2023.1199.},
  keywords = {column generation,diving heuristics,electric vehicles,routing and scheduling},
  file = {/home/axel/zotero-library/Parmentier et al_2023_Electric Vehicle Fleets2.pdf}
}


@misc{cohenLinearProgrammingDecision2019,
  title = {Linear {{Programming}} for {{Decision Processes}} with {{Partial Information}}},
  author = {Cohen, Victor and Parmentier, Axel},
  year = {2019},
  abbr = {Technical Report},
  month = mar,
  number = {arXiv:1811.08880},
  arxiv = {1811.08880},
  eprinttype = {arxiv},
  primaryclass = {math},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1811.08880},
  abstract = {Markov Decision Processes (MDPs) are stochastic optimization problems that model situations where a decision maker controls a system based on its state. Partially observed Markov decision processes (POMDPs) are generalizations of MDPs where the decision maker has only partial information on the state of the system. Decomposable POMDPs are specific cases of POMDPs that enable one to model systems with several components. Such problems naturally model a wide range of applications such as predictive maintenance. Finding an optimal policy for a POMDP is PSPACE-hard and practically challenging. We introduce a mixed integer linear programming (MILP) formulation for POMDPs restricted to the policies that only depend on the current observation, as well as valid inequalities that are based on a probabilistic interpretation of the dependence between variables. The linear relaxation provides a good bound for the usual POMDPs where the policies depend on the full history of observations and actions. Solving decomposable POMDPs is especially challenging due to the curse of dimensionality. Leveraging our MILP formulation for POMDPs, we introduce a linear program based on ``fluid formulation'' for decomposable POMDPs, that provides both a bound on the optimal value and a practically efficient heuristic to find a good policy. Numerical experiments show the efficiency of our approaches to POMDPs and decomposable POMDPs.},
  archiveprefix = {arXiv},
  keywords = {Mathematics - Optimization and Control},
  file = {/home/axel/zotero-library/Cohen_Parmentier_2019_Linear Programming for Decision Processes with Partial Information.pdf;/home/axel/snap/zotero-snap/common/Zotero/storage/DC6B66BC/1811.html}
}


@article{parmentierIntegerProgrammingJunction2020,
  title = {Integer {{Programming}} on the {{Junction Tree Polytope}} for {{Influence Diagrams}}},
  author = {Parmentier, Axel and Cohen, Victor and Lecl{\`e}re, Vincent and Obozinski, Guillaume and Salmon, Joseph},
  year = {2020},
  month = jul,
  journal = {INFORMS Journal on Optimization},
  volume = {2},
  number = {3},
  pages = {209--228},
  publisher = {{INFORMS}},
  issn = {2575-1484},
  doi = {10.1287/ijoo.2019.0036},
  abbr = {Article},
  arxiv = {1902.07039},
  abstract = {Influence diagrams (ID) and limited memory influence diagrams (LIMID) are flexible tools to represent discrete stochastic optimization problems, with the Markov decision process (MDP) and partially observable MDP as standard examples. More precisely, given random variables considered as vertices of an acyclic digraph, a probabilistic graphical model defines a joint distribution via the conditional distributions of vertices given their parents. In an ID, the random variables are represented by a probabilistic graphical model whose vertices are partitioned into three types: chance, decision, and utility vertices. The user chooses the distribution of the decision vertices conditionally to their parents in order to maximize the expected utility. Leveraging the notion of rooted junction tree, we present a mixed integer linear formulation for solving an ID, as well as valid inequalities, which lead to a computationally efficient algorithm. We also show that the linear relaxation yields an optimal integer solution for instances that can be solved by the ``single policy update,'' the default algorithm for addressing IDs.},
  annotation = {ZSCC: 0000003},
}

@article{parmentierLearningApproximateIndustrial2021a,
  title = {Learning to {{Approximate Industrial Problems}} by {{Operations Research Classic Problems}}},
  abbr = {Article},
  hal = {hal-02396091},
  author = {Parmentier, Axel},
  year = {2021},
  month = apr,
  journal = {Operations Research},
  code = {https://pubsonline.informs.org/doi/suppl/10.1287/opre.2020.2094},
  publisher = {{INFORMS}},
  issn = {0030-364X},
  doi = {10.1287/opre.2020.2094},
  abstract = {Practitioners of operations research often consider difficult variants of well-known optimization problems and struggle to find a good algorithm for their variants although decades of research have produced highly efficient algorithms for the well-known problems. We introduce a machine learning for operations research paradigm to build efficient heuristics for such variants: use a machine learning predictor to turn an instance of the variant into an instance of the well-known problem, then solve the instance of the well-known problem, and finally retrieve a solution of the variant from the solution of the well-known problem. This paradigm requires learning the predictor that transforms an instance of the variant into an instance of the well-known problem. We introduce a structured learning methodology to learn that predictor. We illustrate our paradigm and learning methodology on path problems. We, therefore, introduce a maximum likelihood approach to approximate an arbitrary path problem on an acyclic digraph by a usual shortest path problem. Because path problems play an important role as pricing subproblems of column-generation approaches, we introduce matheuristics that leverage our approximations in that context. Numerical experiments show their efficiency on two stochastic vehicle scheduling problems.},
  annotation = {ZSCC: NoCitationData[s0]},
}

@misc{aubin-frankowskiGeneralizationBoundsSurrogate2024,
  title = {Generalization {{Bounds}} of {{Surrogate Policies}} for {{Combinatorial Optimization Problems}}},
  author = {{Aubin-Frankowski}, Pierre-Cyril and De Castro, Yohann and Parmentier, Axel and Rudi, Alessandro},
  year = {2024},
  month = jul,
  abbr = {Preprint},
  number = {arXiv:2407.17200},
  arxiv = {2407.17200},
  primaryclass = {cs, math, stat},
  publisher = {arXiv},
  urldate = {2024-07-25},
  abstract = {A recent stream of structured learning approaches has improved the practical state of the art for a range of combinatorial optimization problems with complex objectives encountered in operations research. Such approaches train policies that chain a statistical model with a surrogate combinatorial optimization oracle to map any instance of the problem to a feasible solution. The key idea is to exploit the statistical distribution over instances instead of dealing with instances separately. However learning such policies by risk minimization is challenging because the empirical risk is piecewise constant in the parameters, and few theoretical guarantees have been provided so far. In this article, we investigate methods that smooth the risk by perturbing the policy, which eases optimization and improves generalization. Our main contribution is a generalization bound that controls the perturbation bias, the statistical learning error, and the optimization error. Our analysis relies on the introduction of a uniform weak property, which captures and quantifies the interplay of the statistical model and the surrogate combinatorial optimization oracle. This property holds under mild assumptions on the statistical model, the surrogate optimization, and the instance data distribution. We illustrate the result on a range of applications such as stochastic vehicle scheduling. In particular, such policies are relevant for contextual stochastic optimization and our results cover this case.},
  archiveprefix = {arXiv}
}


@misc{parmentierLearningStructuredApproximations2023,
  title = {Learning Structured Approximations of Combinatorial Optimization Problems},
  author = {Parmentier, Axel},
  year = {2023},
  abbr = {Preprint},
  code = {https://github.com/axelparmentier/MaximumWeightTwoStageSpanningTree.jl},
  month = feb,
  number = {arXiv:2107.04323},
  arxiv = {2107.04323},
  eprinttype = {arxiv},
  primaryclass = {cs, math},
  publisher = {{arXiv}},
  abstract = {Machine learning pipelines that include a combinatorial optimization layer can give surprisingly efficient heuristics for difficult combinatorial optimization problems. Three questions remain open: which architecture should be used, how should the parameters of the machine learning model be learned, and what performance guarantees can we expect from the resulting algorithms? Following the intuitions of geometric deep learning, we explain why equivariant layers should be used when designing such pipelines, and illustrate how to build such layers on routing, scheduling, and network design applications. We introduce a learning approach that enables to learn such pipelines when the training set contains only instances of the difficult optimization problem and not their optimal solutions, and show its numerical performance on our three applications. Finally, using tools from statistical learning theory, we prove a theorem showing the convergence speed of the estimator. As a corollary, we obtain that, if an approximation algorithm can be encoded by the pipeline for some parametrization, then the learned pipeline will retain the approximation ratio guarantee. On our network design problem, our machine learning pipeline has the approximation ratio guarantee of the best approximation algorithm known and the numerical efficiency of the best heuristic.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Robotics,Mathematics - Optimization and Control},
  file = {/home/axel/zotero-library/Parmentier_2023_Learning structured approximations of combinatorial optimization problems.pdf;/home/axel/snap/zotero-snap/common/Zotero/storage/66IYA6DP/2107.html}
}


@article{parmentierOptimalCounterfactualExplanations2021,
  title = {Optimal {{Counterfactual Explanations}} in {{Tree Ensembles}}},
  author = {Parmentier, Axel and Vidal, Thibaut},
  year = {2021},
  month = jul,
  abbr = {Proceedings},
  journal = {Proceedings of the 38th {{International Conference}} on {{Machine Learning}}},
  pages = {8422--8431},
  publisher = {{PMLR}},
  issn = {2640-3498},
  code = {https://github.com/vidalt/OCEAN},
  pdf = 	 {http://proceedings.mlr.press/v139/parmentier21a/parmentier21a.pdf},
  url = 	 {https://proceedings.mlr.press/v139/parmentier21a.html},
  abstract = {Counterfactual explanations are usually generated through heuristics that are sensitive to the search's initial conditions. The absence of guarantees of performance and robustness hinders trustworthiness. In this paper, we take a disciplined approach towards counterfactual explanations for tree ensembles. We advocate for a model-based search aiming at "optimal" explanations and propose efficient mixed-integer programming approaches. We show that isolation forests can be modeled within our framework to focus the search on plausible explanations with a low outlier score. We provide comprehensive coverage of additional constraints that model important objectives, heterogeneous data types, structural constraints on the feature space, along with resource and actionability restrictions. Our experimental analyses demonstrate that the proposed search approach requires a computational effort that is orders of magnitude smaller than previous mathematical programming algorithms. It scales up to large data sets and tree ensembles, where it provides, within seconds, systematic explanations grounded on well-defined models solved to optimality.},
  langid = {english},
}

@article{parmentierStructuredLearningBased2022,
  title = {Structured Learning Based Heuristics to Solve the Single Machine Scheduling Problem with Release Times and Sum of Completion Times},
  author = {Parmentier, Axel and T'Kindt, Vincent},
  year = {2022},
  month = jun,
  journal = {European Journal of Operational Research},
  issn = {0377-2217},
  doi = {10.1016/j.ejor.2022.06.040},
  arxiv = {2101.01082},
  abbr = {Article},
  abstract = {In this paper, we focus on the solution of a hard single machine scheduling problem by new heuristic algorithms embedding techniques from machine learning and scheduling theory. These heuristics use a dedicated predictor to transform an instance of the hard problem into an instance of a simpler one solved to optimality. The obtained schedule is then transposed to the original problem. We introduce a structured learning approach which enables to fit the predictor using a database of instances with their optimal solution. Computational experiments show that the proposed learning based heuristics are competitive with state-of-the-art heuristics, notably on large instances for which they provide the best results.},
  langid = {english},
  keywords = {Local search,Scheduling,Single machine,Structured learning},
}

@article{poulletShiftPlanningDelay2020,
  title = {Shift {{Planning Under Delay Uncertainty}} at {{Air France}}: {{A Vehicle-Scheduling Problem}} with {{Outsourcing}}},
  shorttitle = {Shift {{Planning Under Delay Uncertainty}} at {{Air France}}},
  author = {Poullet, Julie and Parmentier, Axel},
  year = {2020},
  month = jan,
  journal = {Transportation Science},
  issn = {0041-1655},
  doi = {10.1287/trsc.2019.0960},
  abbr = {Article},
  arxiv = {1811.00171},
  abstract = {Airlines must operate many jobs in airports, such as passenger check-in or runway tasks. In airlines' hubs, airlines generally choose to perform these jobs with their own agents. Shift planning aims at building the sequences of jobs operated by the airline agents and has been widely studied given its impact on operating costs. The impact of delayed flights is generally not taken into account despite the propagation of flight delays along these sequences: If a flight is late, then the agents doing the corresponding jobs are delayed, and may arrive late to their next jobs and delay the corresponding flights. Since delay costs are much higher than the costs of outsourcing jobs, if the agent who is supposed to operate a job is still working elsewhere when the job begins, then airlines tend to outsource the job to their own dedicated team or to a third party. We introduce a stochastic version of the shift-planning problem that takes into account outsourcing costs due to delay. It can be seen as a natural stochastic generalization of the vehicle-scheduling problem in which delayed jobs are outsourced. We propose a column-generation approach to solve it, whose key element is the pricing subproblem algorithm, modeled as a stochastic resource-constrained shortest-path problem. Numerical results on Air France industrial instances show the benefits of using our stochastic version of the shift-planning problem and the efficiency of the solution method. Moving to the stochastic version enables Air France to reduce total operating costs by 3.5\%\textendash 4.8\% on instances with more than 200 jobs, and our algorithm can solve to near optimality instances with up to 400 jobs.},
  annotation = {ZSCC: 0000000},
}

@article{tellacheLinearLexicographicOptimization2024,
  title = {Linear {{Lexicographic Optimization}} and {{Preferential Bidding System}}},
  author = {Tellache, Nour ElHouda and Meunier, Fr{\'e}d{\'e}ric and Parmentier, Axel},
  year = {2024},
  month = mar,
  arxiv = {2201.08907},
  journal = {Transportation Science},
  publisher = {INFORMS},
  abbr = {Article},
  issn = {0041-1655},
  doi = {10.1287/trsc.2022.0372},
  urldate = {2024-05-02},
  abstract = {Some airlines use the preferential bidding system to construct the schedules of their pilots. In this system, the pilots bid on the different activities and the schedules that lexicographically maximize the scores of the pilots according to their seniority are selected. A sequential approach to solve this maximization problem is natural: The problem is first solved with the bids of the most senior pilot, and then it is solved with those of the second most senior without decreasing the score of the most senior, and so on. The literature admits that the structure of the problem somehow imposes such an approach. The problem can be modeled as an integer linear lexicographic program. We propose a new efficient method, which relies on column generation for solving its continuous relaxation and returns proven optimality gaps. To design this column generation, we prove that bounded linear lexicographic programs admit ``primal-dual'' feasible bases, and we show how to compute such bases efficiently. Another contribution on which our method relies is the extension of standard tools for resource-constrained longest path problems to their lexicographic versions. This is useful in our context because the generation of new columns is modeled as a lexicographic resource-constrained longest path problem. Numerical experiments show that this new method is already able to solve to proven optimality industrial instances provided by Air France, with up to 150 pilots. By adding a last ingredient in the resolution of the longest path problems, which exploits the specificity of the preferential bidding system, the method achieves for these instances computational times that are compatible with operational constraints. Supplemental Material: The online appendix is available at https://doi.org/10.1287/trsc.2022.0372.}
}

@article{jungelLearningBasedOnlineOptimization2025,
  title = {Learning-{{Based Online Optimization}} for {{Autonomous Mobility-on-Demand Fleet Control}}},
  arxiv = {2302.03963},
  author = {Jungel, Kai and Parmentier, Axel and Schiffer, Maximilian and Vidal, Thibaut},
  year = {2025},
  month = jun,
  journal = {INFORMS Journal on Computing},
  code = {https://github.com/INFORMSJoC/2024.0637},
  publisher = {INFORMS},
  issn = {1091-9856},
  doi = {10.1287/ijoc.2024.0637},
  abbr = {Journal},
  urldate = {2025-06-10},
  abstract = {Autonomous mobility-on-demand systems are a viable alternative to mitigate many transportation-related externalities in cities, such as rising vehicle volumes in urban areas and transportation-related pollution. However, the success of these systems heavily depends on efficient and effective fleet control strategies. In this context, we study online control algorithms for autonomous mobility-on-demand systems and develop a novel hybrid combinatorial optimization-enriched machine learning pipeline which learns online dispatching and rebalancing policies from optimal full-information solutions. We test our hybrid pipeline on large-scale real-world scenarios with different vehicle fleet sizes and various request densities. We show that our pipeline outperforms greedy and model-predictive control approaches with respect to various key performance indicators (KPIs), for example, by up to 17.1\% and on average by 6.3\% in terms of realized profit, and on average by 4.7\% in terms of satisfied customers. History: Accepted by Andrea Lodi, Area Editor for Design \& Analysis of Algorithms--Discrete. Funding: This work was supported by Deutsche Forschungsgemeinschaft [Grant 449261765]. Supplemental Material: The software that supports the findings of this study is available within the paper and its Supplemental Information (https://pubsonline.informs.org/doi/suppl/10.1287/ijoc.2024.0637) as well as from the IJOC GitHub software repository (https://github.com/INFORMSJoC/2024.0637). The complete IJOC Software and Data Repository is available at https://informsjoc.github.io/.},
  keywords = {central control,mobility-on-demand,online algorithm,structured learning},
}

@article{ahmedDistrictNetDecisionawareLearning2024,
  title = {{{DistrictNet}}: {{Decision-aware}} Learning for Geographical Districting},
  shorttitle = {{{DistrictNet}}},
  journal = {The {{Thirty-eighth Annual Conference}} on {{Neural Information Processing Systems}}},
  author = {Ahmed, Cheikh and Forel, Alexandre and Parmentier, Axel and Vidal, Thibaut},
  year = {2024},
  abbr = {Proceedings},
  arxiv = {2412.08287},
  code = {https://github.com/cheikh025/DistrictNet},
  pdf = {https://openreview.net/forum?id=njwYBFau8E},
  month = nov,
  urldate = {2024-12-18},
  abstract = {Districting is a complex combinatorial problem that consists in partitioning a geographical area into small districts. In logistics, it is a major strategic decision determining operating costs for several years. Solving districting problems using traditional methods is intractable even for small geographical areas and existing heuristics often provide sub-optimal results. We present a structured learning approach to find high-quality solutions to real-world districting problems in a few minutes. It is based on integrating a combinatorial optimization layer, the capacitated minimum spanning tree problem, into a graph neural network architecture. To train this pipeline in a decision-aware fashion, we show how to construct target solutions embedded in a suitable space and learn from target solutions. Experiments show that our approach outperforms existing methods as it can significantly reduce costs on real-world cities.},
}

@article{forelExplainableDataDrivenOptimization2023,
  title = {Explainable {{Data-Driven Optimization}}: {{From Context}} to {{Decision}} and {{Back Again}}},
  shorttitle = {Explainable {{Data-Driven Optimization}}},
  author = {Forel, Alexandre and Parmentier, Axel and Vidal, Thibaut},
  year = {2023},
  month = jul,
  arxiv = {2301.10074},
  pdf = {https://proceedings.mlr.press/v202/forel23a/forel23a.pdf},
  url = {https://proceedings.mlr.press/v202/forel23a},
  code = {https://github.com/alexforel/Explainable-CSO},
  abbr = {Proceedings},
  journal = {Proceedings of the 40th {{International Conference}} on {{Machine Learning}}},
  publisher = {{PMLR}},
  abstract = {Data-driven optimization uses contextual information and machine learning algorithms to find solutions to decision problems with uncertain parameters. While a vast body of work is dedicated to interpreting machine learning models in the classification setting, explaining decision pipelines involving learning algorithms remains unaddressed. This lack of interpretability can block the adoption of data-driven solutions as practitioners may not understand or trust the recommended decisions. We bridge this gap by introducing a counterfactual explanation methodology tailored to explain solutions to data-driven problems. We introduce two classes of explanations and develop methods to find nearest explanations of random forest and nearest-neighbor predictors. We demonstrate our approach by explaining key problems in operations management such as inventory management and routing.},
  archiveprefix = {arXiv},
  keywords = {68T37(Primary); 90-10 (Secondary),Computer Science - Machine Learning,I.2.8,Mathematics - Optimization and Control}
}

@article{ardisson2024cfopt,
      title={CF-OPT: Counterfactual Explanations for Structured Prediction}, 
      author={Vivier-Ardisson, Germain and Forel, Alexandre and Parmentier, Axel and Vidal, Thibaut},
        year = {2024},
        month = jul,
        abbr = {Proceedings},
        arxiv = {2405.18293},
        abstract = {Optimization layers in deep neural networks have enjoyed a growing popularity in structured learning, improving the state of the art on a variety of applications. Yet, these pipelines lack interpretability since they are made of two opaque layers: a highly non-linear prediction model, such as a deep neural network, and an optimization layer, which is typically a complex black-box solver. Our goal is to improve the transparency of such methods by providing counterfactual explanations. We build upon variational autoencoders a principled way of obtaining counterfactuals: working in the latent space leads to a natural notion of plausibility of explanations. We finally introduce a variant of the classic loss for VAE training that improves their performance in our specific structured context. These provide the foundations of CF-OPT, a first-order optimization algorithm that can find counterfactual explanations for a broad class of structured learning architectures. Our numerical results show that both close and plausible explanations can be obtained for problems from the recent literature.},
        code = {https://github.com/GermainVivierArdisson/CF-OPT},
        journal = {Accepted at the 41st {{International Conference}} on {{Machine Learning}}},
        publisher = {{PMLR}}
}

@article{demelas2023predicting,
      title={Predicting Accurate Lagrangian Multipliers for Mixed Integer Linear Programs}, 
      author={Francesco Demelas and Joseph Le Roux and Mathieu Lacroix and Axel Parmentier},
        year = {2024},
        month = jul,
        abbr = {Proceedings},
        journal = {Accepted at the 41st {{International Conference}} on {{Machine Learning}}},
        publisher = {{PMLR}},
      abstract = {Lagrangian relaxation stands among the most efficient approaches for solving a Mixed Integer Linear Programs (MILP) with difficult constraints. Given any duals for these constraints, called Lagrangian Multipliers (LMs), it returns a bound on the optimal value of the MILP, and Lagrangian methods seek the LMs giving the best such bound. But these methods generally rely on iterative algorithms resembling gradient descent to maximize the concave piecewise linear dual function: the computational burden grows quickly with the number of relaxed constraints. We introduce a deep learning approach that bypasses the descent, effectively amortizing the local, per instance, optimization. A probabilistic encoder based on a graph convolutional network computes high-dimensional representations of relaxed constraints in MILP instances. A decoder then turns these representations into LMs. We train the encoder and decoder jointly by directly optimizing the bound obtained from the predicted multipliers. Numerical experiments show that our approach closes up to 85\textasciitilde\textbackslash\% of the gap between the continuous relaxation and the best Lagrangian bound, and provides a high quality warm-start for descent based Lagrangian methods.},
      arxiv={2310.14659},
      primaryClass={cs.LG}
}

@misc{greifCombinatorialOptimizationMachine2024,
  title = {Combinatorial {{Optimization}} and {{Machine Learning}} for {{Dynamic Inventory Routing}}},
  author = {Greif, Toni and Bouvier, Louis and Flath, Christoph M. and Parmentier, Axel and Rohmer, Sonja U. K. and Vidal, Thibaut},
  abbr = {Preprint},
  year = {2024},
  month = feb,
  arxiv = {2402.04463},
  abstract = {We introduce a combinatorial optimization-enriched machine learning pipeline and a novel learning paradigm to solve inventory routing problems with stochastic demand and dynamic inventory updates. After each inventory update, our approach reduces replenishment and routing decisions to an optimal solution of a capacitated prize-collecting traveling salesman problem for which well-established algorithms exist. Discovering good prize parametrizations is non-trivial; therefore, we have developed a machine learning approach. We evaluate the performance of our pipeline in settings with steady-state and more complex demand patterns. Compared to previous works, the policy generated by our algorithm leads to significant cost savings, achieves lower inference time, and can even leverage contextual information.},
  archiveprefix = {arxiv},
  keywords = {Mathematics - Optimization and Control}
}

@article{WardropNetTrafficFlow2024,
  title = {{{WardropNet}}: {{Traffic Flow Predictions}} via {{Equilibrium-Augmented Learning}}},
  shorttitle = {{{WardropNet}}},
  journal = {The {{Thirteenth International Conference}} on {{Learning Representations}}},
  abbr = {Proceedings},
  year = {2025},
  month = apr,
  arxiv = {2410.06656},
  pdf = {https://openreview.net/forum?id=7FHSPd3SRE},
  urldate = {2025-01-30},
  abstract = {When optimizing transportation systems, anticipating traffic flows is a central element. Yet, computing such traffic equilibria remains computationally expensive. Against this background, we introduce a novel combinatorial optimization augmented neural network architecture that allows for fast and accurate traffic flow predictions. We propose WardropNet, a neural network that combines classical layers with a subsequent equilibrium layer: the first ones inform the latter by predicting the parameterization of the equilibrium problem's latency functions. Using supervised learning we minimize the difference between the actual traffic flow and the predicted output. We show how to leverage a Bregman divergence fitting the geometry of the equilibria, which allows for end-to-end learning. WardropNet outperforms pure learning-based approaches in predicting traffic equilibria for realistic and stylized traffic scenarios. On realistic scenarios, WardropNet improves on average for time-invariant predictions by up to 72{\textbackslash}\% and for time-variant predictions by up to 23{\textbackslash}\% over pure learning-based approaches.},
  langid = {english},
}

@article{batyCombinatorialOptimizationEnrichedMachine2024,
  title = {Combinatorial {{Optimization-Enriched Machine Learning}} to {{Solve}} the {{Dynamic Vehicle Routing Problem}} with {{Time Windows}}},
  author = {Baty, L{\'e}o and Jungel, Kai and Klein, Patrick S. and Parmentier, Axel and Schiffer, Maximilian},
  year = {2024},
  month = feb,
  journal = {Transportation Science},
  publisher = {INFORMS},
  doi = {10.1287/trsc.2023.0107},
  code = {https://github.com/tumBAIS/euro-meets-neurips-2022},
  urldate = {2024-03-29},
  abstract = {With the rise of e-commerce and increasing customer requirements, logistics service providers face a new complexity in their daily planning, mainly due to efficiently handling same day deliveries. Existing multi-stage stochastic optimization approaches that allow to solve the underlying dynamic vehicle routing problem are either computationally too expensive for an application in online settings, or -- in the case of reinforcement learning -- struggle to perform well on high-dimensional combinatorial problems. To mitigate these drawbacks, we propose a novel machine learning pipeline that incorporates a combinatorial optimization layer. We apply this general pipeline to a dynamic vehicle routing problem with dispatching waves, which was recently promoted in the EURO Meets NeurIPS Vehicle Routing Competition at NeurIPS 2022. Our methodology ranked first in this competition, outperforming all other approaches in solving the proposed dynamic vehicle routing problem. With this work, we provide a comprehensive numerical study that further highlights the efficacy and benefits of the proposed pipeline beyond the results achieved in the competition, e.g., by showcasing the robustness of the encoded policy against unseen instances and scenarios.},
  abbr = {Article},
  arxiv = {2304.00789},
}



@misc{parmentierStochasticShortestPaths2014,
  title = {Stochastic {{Shortest Paths}} and {{Risk Measures}}},
  author = {Parmentier, Axel and Meunier, Fr{\'e}d{\'e}ric},
  year = {2014},
  month = sep,
  number = {arXiv:1408.0272},
  arxiv = {1408.0272},
  eprinttype = {arxiv},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1408.0272},
  abbr = {Technical Report},
  abstract = {We consider three shortest path problems in directed graphs with random arc lengths. For the first and the second problems, a risk measure is involved. While the first problem consists in finding a path minimizing this risk measure, the second one consists in finding a path minimizing a deterministic cost, while satisfying a constraint on the risk measure. We propose algorithms solving these problems for a wide range of risk measures, which includes among several others the \$CVaR\$ and the probability of being late. Their performances are evaluated through experiments. One of the key elements in these algorithms is the use of stochastic lower bounds that allow to discard partial solutions. Good stochastic lower bounds are provided by the so-called Stochastic Ontime Arrival Problem. This latter problem is the third one studied in this paper and we propose a new and very efficient algorithm solving it. Complementary discussions on the complexity of the problems are also provided.},
  archiveprefix = {arXiv},
  keywords = {90B99,Computer Science - Data Structures and Algorithms},
  file = {/home/axel/zotero-library/Parmentier_Meunier_2014_Stochastic Shortest Paths and Risk Measures.pdf}
}
@article{samaranayakeMathematicalFrameworkDelay2017,
  title = {A Mathematical Framework for Delay Analysis in Single Source Networks},
  author = {Samaranayake, Samitha and Parmentier, Axel and Xuan, Ethan and Bayen, Alexandre},
  year = {2017},
  month = sep,
  journal = {Networks and Heterogeneous Media},
  abbr = {Article},
  volume = {12},
  number = {1},
  pages = {113--145},
  publisher = {{Networks and Heterogeneous Media}},
  issn = {1556-1801},
  doi = {10.3934/nhm.2017005},
  abstract = {This article presents a mathematical framework for modeling heterogeneous flow networks with a single source and multiple sinks with no merging. The traffic is differentiated by the destination (i.e. Lagrangian flow) and different flow groups are assumed to satisfy the first-in-first-out (FIFO) condition at each junction. The queuing in the network is assumed to be contained at each junction node and spill-back to the previous junction is ignored. We show that this model leads to a well-posed problem for computing the dynamics of the system and prove that the solution is unique through a mathematical derivation of the model properties. The framework is then used to analytically prescribe the delays at each junction of the network and across any sub-path, which is the main contribution of the article. This is a critical requirement when solving control and optimization problems over the network, such as system optimal network routing and solving for equilibrium behavior. In fact, the framework provides analytical expressions for the delay at any node or sub-path as a function of the inflow at any upstream node. Furthermore, the model can be solved numerically using a very simple and efficient feed forward algorithm. We demonstrate the versatility of the framework by applying it to two example networks, a single path of multiple bottlenecks and a diverge junction with complex junction dynamics.},
  langid = {english}
}
@article{samaranayakeSolvingUserEquilibrium2015,
  title = {Solving the User Equilibrium Departure Time Problem at an Off-Ramp with Incentive Compatible Cost Functions},
  journal = {2015 {{European Control Conference}} ({{ECC}})},
  author = {Samaranayake, Samitha and Parmentier, Axel and Xuan, Yiguang and Bayen, Alexandre},
  year = {2015},
  month = jul,
  abbr = {Proceedings},
  pages = {3465--3471},
  doi = {10.1109/ECC.2015.7331070},
  abstract = {We consider the equilibrium departure time problem for a set of vehicles that travel through a network with capacity restrictions and need to reach a destination at a fixed time. The vehicles incur a penalty for both any queuing delays and arriving at the destination early or late. In particular, we consider the case of a congested off-ramp, which is a common occurrence next to commercial hubs during the morning commute, and has the added negative effect of reducing the capacity on the freeway for through traffic. We study the use of incentives and tolls to manipulate the equilibrium departure times of the exiting vehicles and thereby mitigate the impact on through traffic. Our main result is to show the existence and uniqueness properties of the departure time equilibrium for a general class of delay and arrival time cost functions, which allows for discontinuities in the arrival cost function. This enables the use of step incentives or tolls, which are the mostly common strategies used in practice. Our results also apply to the Vickrey single bottleneck equilibrium, which is a special case of our network.},
  keywords = {Analytical models,Cost function,Delays,Schedules,Traffic control,Vehicles}
}
@article{bouvierSolvingContinentScaleInventory2024,
  title = {Solving a {{Continent-Scale Inventory Routing Problem}} at {{Renault}}},
  author = {Bouvier, Louis and Dalle, Guillaume and Parmentier, Axel and Vidal, Thibaut},
  year = {2024},
  month = jan,
  journal = {Transportation Science},
  volume = {58},
  number = {1},
  pages = {131--151},
  publisher = {INFORMS},
  issn = {0041-1655},
  doi = {10.1287/trsc.2022.0342},
  urldate = {2024-05-02},
  abstract = {This paper is the fruit of a partnership with Renault. Their reverse logistic requires solving a continent-scale multiattribute inventory routing problem (IRP). With an average of 30 commodities, 16 depots, and 600 customers spread across a continent, our instances are orders of magnitude larger than those in the literature. Existing algorithms do not scale, so we propose a large neighborhood search (LNS). To make it work, (1) we generalize existing split delivery vehicle routing problems and IRP neighborhoods to this context, (2) we turn a state-of-the-art matheuristic for medium-scale IRP into a large neighborhood, and (3) we introduce two novel perturbations: the reinsertion of a customer and that of a commodity into the IRP solution. We also derive a new lower bound based on a flow relaxation. In order to stimulate the research on large-scale IRP, we introduce a library of industrial instances. We benchmark our algorithms on these instances and make our code open source. Extensive numerical experiments highlight the relevance of each component of our LNS. Funding: This work was supported by Renault Group. Supplemental Material: The online appendix is available at https://doi.org/10.1287/trsc.2022.0342.},
  keywords = {large neighborhood search,mathematical programming,Multi-attribute inventory routing problem},
  arxiv = {2209.00412},
  abbr = {Article},
  code = {https://github.com/LouisBouvier/InventoryRoutingLNS.jl}
}

